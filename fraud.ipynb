{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kampus Merdeka 6: IBM & Skilvul\n",
    "## Capstone Banking & Finance Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition Fraud Detection App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latar Belakang\n",
    "\n",
    "**Penipuan dalam sistem keuangan, termasuk transaksi kartu kredit, perbankan online, dan e-commerce, menimbulkan ancaman signifikan bagi lembaga keuangan dan pelanggan mereka. Hal ini dapat mengakibatkan kerugian finansial yang besar dan merusak reputasi lembaga tersebut. Dengan meningkatnya transaksi online dan perbankan digital, mendeteksi aktivitas penipuan menjadi semakin kompleks dan menantang. Oleh karena itu, ada kebutuhan mendesak untuk sistem deteksi penipuan yang efektif yang dapat mengidentifikasi dan mengurangi aktivitas penipuan secara real-time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tujuan\n",
    "\n",
    "**Digunakan untuk mendeteksi penipuan berdasarkan nilai binary [0,1] pada kolom isFraud.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data yang akan dipakai\n",
    "\n",
    "**Kami menggunakan data yang bersumber dari kaggle dengan link sebagai berikut (https://www.kaggle.com/datasets/chitwanmanchanda/fraudulent-transactions-data/data).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metode\n",
    "\n",
    "**Metode yang digunakan yaitu metode Binary Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Fraud.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data | Membersihkan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_counts = data['isFraud'].value_counts()\n",
    "\n",
    "print(fraud_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isFraud.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data (EDA) | Eksplorasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus atau konversi kolom non-numerik\n",
    "data_numeric = data.select_dtypes(include=[np.number])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(21,10))\n",
    "sns.set_context('poster')\n",
    "corr = data_numeric.corr()\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns,cmap='gist_rainbow', annot = True)\n",
    "ax.set_title('Collinearity of Feature Attributes')\n",
    "plt.savefig('cormap.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution graphs (histogram/bar graph) of column data\n",
    "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
    "    nunique = df.nunique()\n",
    "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
    "    nRow, nCol = df.shape\n",
    "    columnNames = list(df)\n",
    "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
    "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
    "    for i in range(min(nCol, nGraphShown)):\n",
    "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
    "        columnDf = df.iloc[:, i]\n",
    "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
    "            valueCounts = columnDf.value_counts()\n",
    "            valueCounts.plot.bar()\n",
    "        else:\n",
    "            columnDf.hist()\n",
    "        plt.ylabel('counts')\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.title(f'{columnNames[i]} (column {i})')\n",
    "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "def plotCorrelationMatrix(df, graphWidth):\n",
    "    filename = df.dataframeName\n",
    "    df = df.dropna('columns') # drop columns with NaN\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    if df.shape[1] < 2:\n",
    "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
    "        return\n",
    "    corr = df.corr()\n",
    "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
    "    corrMat = plt.matshow(corr, fignum = 1)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.colorbar(corrMat)\n",
    "    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter and density plots\n",
    "def plotScatterMatrix(df, plotSize, textSize):\n",
    "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
    "    # Remove rows and columns that would lead to df being singular\n",
    "    df = df.dropna('columns')\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    columnNames = list(df)\n",
    "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
    "        columnNames = columnNames[:10]\n",
    "    df = df[columnNames]\n",
    "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
    "    corrs = df.corr().values\n",
    "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
    "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
    "    plt.suptitle('Scatter and Density Plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print percentage of questions where target == 1\n",
    "percent = (len(data.loc[data.isFraud==1])) / (len(data.loc[data.isFraud == 0])) * 100\n",
    "print(f\"Percentage of Fraudulent Transanctions in the Dataset: {percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"type\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all categorical columns in the dataframe\n",
    "catCols = [col for col in data.columns if data[col].dtype==\"O\"]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "for item in catCols:\n",
    "    data[item] = lb_make.fit_transform(data[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training | Pelatihan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below will be used to evaluate different metrics of the algorithms used here.\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision Score: \", precision_score(y_test, y_pred))\n",
    "    print(\"Recall Score: \", recall_score(y_test, y_pred))\n",
    "    print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "\n",
    "    df = {'y_Actual': y_test, 'y_Predicted': y_pred}\n",
    "\n",
    "    df1 = pd.DataFrame(df, columns = ['y_Actual','y_Predicted'])\n",
    "\n",
    "    clf_confusion_matrix = pd.crosstab(df['y_Predicted'], df['y_Actual'], rownames = ['Predicted'], colnames=['Actual'])\n",
    "\n",
    "    sns.heatmap(clf_confusion_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection | Pemilihan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('isFraud', axis=1)\n",
    "y = data.isFraud\n",
    "\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DummyClassifier to predict only target 0\n",
    "dummy = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "# checking unique labels\n",
    "print('Unique predicted labels: ', (np.unique(dummy_pred)))\n",
    "\n",
    "# checking accuracy\n",
    "evaluate_model(y_test, dummy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperti yang dapat kita lihat, Dummy Classifier secara akurat memprediksi transaksi non-penipuan dengan akurasi 99,8%, tetapi itu bukan fokus kami. Kita harus dapat memprediksi transaksi penipuan secara akurat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection | Pemilihan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling the data as is\n",
    "# Train model\n",
    "lr = LogisticRegression()\n",
    "model1 = lr.fit(X_train, y_train)\n",
    " \n",
    "# Predict on training set\n",
    "lr_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique values\n",
    "predictions = pd.DataFrame(lr_pred)\n",
    "predictions[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Logistic Regression berkinerja cukup baik tetapi skor recall masih sangat rendah. Lebih banyak pekerjaan yang perlu dilakukan dengan himpunan data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection | Pemilihan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "evaluate_model(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique values\n",
    "predictions = pd.DataFrame(rfc_pred)\n",
    "predictions[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita dapat melihat bahwa Random Forest memiliki skor terbaik sejauh ini di berbagai metrik dengan skor recall 77% dan skor F1 86%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'FraudDetect_model.sav'\n",
    "pickle.dump(rfc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection | Pemilihan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model terakhir yang digunakan yang memiliki skor terbaik di semua metrik adalah Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kesimpulan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dari ketiga report diatas yang cukup sekiranya untuk dikatakan bagus yaitu Random Forest Classifier karena mendapat skor recall 77%, dan mendapat skor f1 sebesar 90%. Dan secara keseluruhan, classification model memiliki akurasi 99%.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
